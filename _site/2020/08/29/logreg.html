<!DOCTYPE html>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Regresion Logistica | data,math,code</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<!--[if lte IE 8]><script src="/home/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/home/assets/css/main.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="/home/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="/home/assets/css/ie8.css" /><![endif]-->
</head>


<body>

    <!-- Wrapper -->
<div id="wrapper">

<!-- Header -->
<header id="header">
	<a href="http://localhost:4000/home/" class="logo"><strong>data,math,code</strong> <span>carabedo</span></a>
	<nav>
		<a href="#menu">Menu</a>
	</nav>
</header>

<!-- Menu -->
<nav id="menu">
	<ul class="links">
        
		    
		
		    
		
		    
		
		    
		
		    
		        <li><a href="http://localhost:4000/home/">Home</a></li>
	    	
		
		    
		
		    
		
		    
		
		
		    
		
		    
		        <li><a href="http://localhost:4000/home/all_posts.html">All posts</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/pages/cloud.html">cloud & security</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/pages/dev.html">web development</a></li>
		    
		
		    
		
		    
		        <li><a href="http://localhost:4000/home/pages/machine.html">machine learning</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/pages/presentaciones.html">clases</a></li>
		    
		
	</ul>

</nav>
 
    
    
<!-- Main -->
<div id="main" class="alt">

<!-- One -->
<section id="one" >
	<div class="inner" style="width : 60%">
		<header class="major">
			<h1>Regresion Logistica</h1>
		</header>
		
		<p><br /></p>

<p>Miremos un problema simple de clasificacion, donde tengo datos con una sola variable explicativa y mi variable objetivo a predecir puede ser de dos clases (0,1).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</code></pre></div></div>

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://muydipalma.github.io/home/fig0.html" height="525" width="100%"></iframe>

<p>Visualizando los datos, nos damos cuenta que no es lo eficiente ajustar esto con una recta, necesitamos algo un poco mas sofisticado. Una funcion que nos puede servir es la funcion sigmoide:</p>

<p>Como en la regresion lineal, debemos definir una funcion de costo para mis parametros y minizarla utilizando algun metodo iterativo como es el caso de descenso por gradiente. De esta manera encontraremos los parametros de la funcion sigmoide que mejor describan mis datos.
<br /></p>
<h2 id="regresion-logistica-desde-0">Regresion Logistica desde 0</h2>
<p><br /></p>

<p>Podemos implementar lo que acabo de comentar creando una clase de python, dandole el mismo formato que las clases de SKLEARN (con los metodos .fit, .predict):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">copy</span> <span class="k">as</span> <span class="n">copy</span>

<span class="k">class</span> <span class="nc">logisticreg</span><span class="p">:</span>
    
    <span class="c1"># iteracion que busca minizar la funcion de costo haciendo descenso gradiente
</span>    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">__add_intercept</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        
        <span class="c1"># inicializamos los betas, ponemos betas=0             
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="c1"># loop principal
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_iter</span><span class="p">):</span>
            
            <span class="c1"># calculo p inicial
</span>            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">__sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            
            <span class="c1"># calculo el gradiente
</span>            <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span> <span class="o">/</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span>
            
            <span class="c1"># asigno los nuevos betas en la direccion del gradiente
</span>            <span class="c1"># y con el paso lr
</span>            
            <span class="bp">self</span><span class="p">.</span><span class="n">theta</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">gradient</span>
            
            <span class="c1"># me guardo los betas de cada iteracion
</span>            <span class="n">p</span><span class="o">=</span><span class="n">copy</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">theta</span><span class="p">[:])</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">coefs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">ls</span><span class="o">=</span><span class="n">copy</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">__loss</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lss</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ls</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="bp">True</span><span class="p">):</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span>
                <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">__sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">i</span><span class="p">,</span><span class="bp">self</span><span class="p">.</span><span class="n">__loss</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s"> </span><span class="se">\t</span><span class="s">'</span><span class="p">)</span>    
            <span class="c1">#listo!
</span>            
    <span class="c1">#usa los betas encontrados
</span>    <span class="k">def</span> <span class="nf">predict_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">__add_intercept</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">__sigmoid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">theta</span><span class="p">))</span>
    
    <span class="c1">#usamos el threshold para la clasificacion
</span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">predict_prob</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    
                
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">num_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
                 <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_iter</span> <span class="o">=</span> <span class="n">num_iter</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="n">fit_intercept</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">coefs</span><span class="o">=</span><span class="nb">list</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lss</span><span class="o">=</span><span class="nb">list</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">__add_intercept</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">intercept</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    
    <span class="c1">#sigmoide
</span>    <span class="k">def</span> <span class="nf">__sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
    

    <span class="c1">#funcion de costo
</span>    <span class="k">def</span> <span class="nf">__loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">)).</span><span class="n">mean</span><span class="p">()</span>                
</code></pre></div></div>
<p><br />
Ahora podemos ver como van cambiando los parametros de la funcion sigmoide a medida que vamos iterando la minizacion de la funcion de costo:
<br /></p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://muydipalma.github.io/home/assets/img/figi.html" height="900" width="750"></iframe>

<p>Como se ve para la iteracion i=100000, la sigmoide se ajusta muy bien a los datos, lo que nos permite predecir a que clase pertenece una nueva observacion.</p>

	</div>
</section>

</div>

    <!-- Contact -->



<!-- Footer -->
	<footer id="footer">
		<div class="inner">
			<ul class="icons">
				
					
						<li>
							<a href="https://github.com/carabedo" class="icon alt fa-github" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
								<span class="label">GitHub</span>
							</a>
						</li>
					
				
			</ul>
			<ul class="copyright">
				<li>Design: <a href="https://html5up.net" target="_blank">HTML5 UP</a></li>
		

			</ul>
		</div>
	</footer>

</div>

<!-- Scripts -->
	<script src="http://localhost:4000/home/assets/js/jquery.min.js"></script>
	<script src="http://localhost:4000/home/assets/js/jquery.scrolly.min.js"></script>
	<script src="http://localhost:4000/home/assets/js/jquery.scrollex.min.js"></script>
	<script src="http://localhost:4000/home/assets/js/skel.min.js"></script>
	<script src="http://localhost:4000/home/assets/js/util.js"></script>
	<!--[if lte IE 8]><script src="http://localhost:4000/home/assets/js/ie/respond.min.js"></script><![endif]-->
	<script src="http://localhost:4000/home/assets/js/main.js"></script>


</body>

</html>
